---
title: "A Comparative Exploration of Orthogonal Signal Correction Methods"
description: "Orthogonal signal correction (OSC) is a powerful preprocessing technique frequently used to remove variation in spectral data that is orthogonal to the property of interest. Over the years, several implementations of OSC have emerged, with the most notable being those by Wold et al., Sjöblom et al., and Fearn. This post compares these three methods, exploring their algorithmic approaches and practical implications."
author: "Christian L. Goueguel"
date: "5/25/2023"
image: "cover.png"
categories:
  - R
  - Preprocessing
  - Chemometrics
  - Machine Learning
  - Spectroscopy
---

::: justified
![Photo by [Jonatan Pie](https://unsplash.com/photos/a-body-of-water-surrounded-by-mountains-and-clouds-_b2hvhIXGI8?utm_content=creditShareLink&utm_medium=referral&utm_source=unsplash).](cover.png){fig-align="center"}

Wold's method was the first formal OSC algorithm. It operates iteratively to identify orthogonal components unrelated to the dependent variable $Y$. The method leverages a combination of principal component analysis (PCA) and partial least squares (PLS). Sjöblom's approach builds on Wold's by introducing a direct orthogonalization step. The algorithm emphasizes calibration transfer, making it especially useful for standardizing spectral datasets across instruments or conditions. Whereas, Fearn proposed a mathematically elegant version of OSC, simplifying the computation by leveraging matrix operations. The method directly orthogonalizes $X$ using a singular value decomposition (SVD) of a residual matrix.

## Wold's OSC Algorithm

The Wold algorithm is like a precise sculptor of spectroscopic data. It uses Partial Least Squares (PLS) regression to systematically remove spectral variations that are unrelated to the target variable. The key steps involve:

-   Iteratively identifying orthogonal components
-   Projecting out signals that don't correlate with the target
-   Refining the correction through multiple computational passes

Think of it as a meticulous data cleaning process that carefully separates meaningful signal from background noise.

### Framework:

Wold's OSC identifies components in $X$ orthogonal to $Y$ through iterative deflation. The primary steps are:

-   Project $X$ onto $Y$ to identify the $Y$-relevant information.
-   Extract the orthogonal scores $t$ from $X$, ensuring they are independent of $Y$.
-   Subtract the contribution of these orthogonal components from $X$.
-   Repeat for multiple components until a predefined number of orthogonal components ($n_{\text{comp}}$) is reached.

### Mathematical Steps:

Initialize $t$, the first score vector (e.g., using PCA on $X$).

1.  Deflate $t$ using $Y$: $t_{\text{new}} = t - Y(Y^\top Y)^{-1}Y^\top t$
2.  Calculate a loading vector $p$ from $t_{\text{new}}$ to model $X$: $p = \frac{X^\top t_{\text{new}}}{t_{\text{new}}^\top t_{\text{new}}}$
3.  Deflate $X$: $X_{\text{new}} = X - t_{\text{new}} p^\top$
4.  Repeat until $n_{\text{comp}}$.

```{r}
wold_osc <- function(x, y, ncomp, tol, max.iter) {
  x_original <- x
  ps <- ws<- ts <- vector("list", ncomp)
  for (i in seq_len(ncomp)) {
    pc <- stats::prcomp(x, center = FALSE)
    t <- pc$x[, 1]
    dif <- 1
    iter <- 0
    while (dif > tol && iter < max.iter) {
      iter <- iter + 1
      t_new <- t - y %*% MASS::ginv(crossprod(y, y)) %*% crossprod(y, t)
      plsFit <- pls::simpls.fit(x, t_new, ncomp, center = FALSE)
      w <- plsFit$coefficients[ , , ncomp]
      w <- w / sqrt(sum(w^2))
      t_new <- x %*% w
      dif <- sqrt(sum((t_new - t)^2) / sum(t_new^2))
      t <- t_new
    }
    p <- crossprod(t, x) %*% MASS::ginv(crossprod(t, t_new))
    x <- x - tcrossprod(t, p)
    ws[[i]] <- w
    ps[[i]] <- p
    ts[[i]] <- t
  }
  w_ortho <- do.call(cbind, ws)
  p_ortho <- do.call(cbind, ps)
  t_ortho <- do.call(cbind, ts)
  x_osc <- x_original - x_original %*% tcrossprod(w_ortho, p_ortho)

  R2 <- sum(x_osc^2) / sum(x_original^2) * 100
  angle <- crossprod(t_ortho, y)
  norm <- MASS::ginv(sqrt(apply(t_ortho^2, 2, sum) * sum(y^2)))
  angle <- t(angle) %*% t(norm)
  angle <- mean(acos(angle) * 180 / pi)

  res <- list(
    "correction" = tibble::as_tibble(x_osc),
    "weights" = tibble::as_tibble(w_ortho),
    "scores" = tibble::as_tibble(t_ortho),
    "loadings" = tibble::as_tibble(p_ortho),
    "angle" = angle,
    "R2" = R2
  )
  return(res)
}
```

## Sjöblom's OSC Algorithm

jöblom's approach is the pragmatic cousin of the Wold method. It:

-   Uses a more direct weight calculation technique
-   Focuses on quickly identifying and removing orthogonal variations
-   Requires fewer computational iterations
-   Provides a computationally efficient alternative to more complex methods

It's like a quick, no-nonsense cleaning process for spectroscopic data.

### Framework:

-   Sjöblom's OSC refines Wold's approach by emphasizing a more direct projection of $X$ orthogonal to $Y$.
-   It uses similar steps but simplifies certain iterative aspects, focusing on the orthogonal direction more explicitly.

### Mathematical Steps:

1.  Identify a direction vector $w$ from $X$ and $t$, the orthogonal scores $w = \frac{X^\top t}{t^\top t}$​
2.  Normalize $w$: $w = \frac{w}{\|w\|}$​
3.  Deflate $t$ from $Y$ as in Wold's method.
4.  Remove the orthogonal variation from $X$: $X_{\text{new}} = X - t p^\top$
5.  Iterate for each component.

```{r}
sjoblom_osc <- function(x, y, ncomp, tol, max.iter) {
  x_original <- x
  ps <- ws <- ts <- vector("list", ncomp)
  for (i in seq_len(ncomp)) {
    pc <- stats::prcomp(x, center = FALSE)
    t <- pc$x[, 1]
    dif <- 1
    iter <- 0
    while (dif > tol && iter < max.iter) {
      iter <- iter + 1
      t_new <- t - y %*% MASS::ginv(crossprod(y, y)) %*% crossprod(y, t)
      w <- crossprod(x, t_new) %*% MASS::ginv(crossprod(t_new, t_new))
      w <- w / sqrt(sum(w^2))
      t_new <- x %*% w
      dif <- sqrt(sum((t_new - t)^2) / sum(t_new^2))
      t <- t_new
    }
    plsFit <- pls::simpls.fit(x, t, ncomp)
    w <- plsFit$coefficients[ , , ncomp]
    t <- x %*% w
    t <- t - y %*% MASS::ginv(crossprod(y, y)) %*% crossprod(y, t)
    p <- crossprod(x, t) %*% MASS::ginv(crossprod(t, t))
    x <- x - tcrossprod(t, p)
    ws[[i]] <- w
    ps[[i]] <- p
    ts[[i]] <- t
  }
  w_ortho <- do.call(cbind, ws)
  p_ortho <- do.call(cbind, ps)
  t_ortho <- do.call(cbind, ts)
  x_osc <- x_original - x_original %*% tcrossprod(w_ortho, p_ortho)

  R2 <- sum(x_osc^2) / sum(x_original^2) * 100
  angle <- crossprod(t_ortho, y)
  norm <- MASS::ginv(sqrt(apply(t_ortho^2, 2, sum) * sum(y^2)))
  angle <- t(angle) %*% t(norm)
  angle <- mean(acos(angle) * 180 / pi)

  res <- list(
    "correction" = tibble::as_tibble(x_osc),
    "weights" = tibble::as_tibble(w_ortho),
    "scores" = tibble::as_tibble(t_ortho),
    "loadings" = tibble::as_tibble(p_ortho),
    "angle" = angle,
    "R2" = R2
  )
  return(res)
}
```

## Fearn's OSC Algorithm

Fearn's method stands out by using Singular Value Decomposition (SVD) as its foundation. Its unique characteristics include:

-   Preprocessing data through matrix decomposition
-   Creating orthogonal components using eigenvalue analysis
-   Handling complex spectral structures more robustly
-   Particularly effective with datasets having clear orthogonal patterns

Imagine it as a mathematical lens that reshapes your data's underlying structure.

### Framework:

-   Fearn’s OSC is conceptually different, relying on Singular Value Decomposition (SVD) for a more robust decomposition of the orthogonal signal.
-   Instead of iterative refinement, Fearn's method isolates orthogonal components through SVD of the residual matrix $Z = X - P_Y X$, where $P_Y$ projects $X$ onto $Y$.

### Mathematical Steps:

1.  Compute the residual matrix $Z$: $Z = X - Y (Y^\top Y)^{-1} Y^\top X$
2.  Perform SVD on $Z$: $Z = U S V^\top$
3.  Extract the first $n_{\text{comp}}$ components from $V$ and reconstruct the orthogonal scores $t$ and loadings $p$: $t = Z V_{:, i}, \quad p = \frac{X^\top t}{t^\top t}$
4.  Deflate $X$: $X_{\text{new}} = X - t p^\top$

```{r}
fearn_osc <- function(x, y, ncomp, tol, max.iter) {
  x_original <- x
  ps <- ws <- ts <- vector("list", ncomp)
  m <- diag(row(x)) - crossprod(x, y) %*% MASS::ginv(crossprod(y, x) %*% crossprod(x, y)) %*% crossprod(y, x)
  z <- x %*% m
  decomp <- svd(t(z))
  u <- decomp$u
  s <- decomp$d
  v <- decomp$v
  g <- diag(s[1:ncomp])
  c <- v[, 1:ncomp, drop = FALSE]

  for (i in seq_len(ncomp)) {
    w_old <- rep(0, ncol(x))
    w_new <- rep(1, ncol(x))
    dif <- 1
    iter <- 0
    while (dif > tol && iter < max.iter) {
      iter <- iter + 1
      w_old <- w_new
      t_new <- c[, i] %*% g[i, i]
      p_new <- tcrossprod(x, t_new) / tcrossprod(t_new, t_new)
      w_new <- m %*% tcrossprod(x, p_new)
      dif <- sqrt(sum((w_new - w_old)^2) / sum(w_new^2))
    }
    ws[[i]] <- w_new
    ts[[i]] <- c[, i] %*% g[i, i]
    ps[[i]] <- tcrossprod(x, t[[i]]) / tcrossprod(t[[i]], t[[i]])
  }
  w_ortho <- do.call(cbind, ws)
  t_ortho <- do.call(cbind, ts)
  p_ortho <- do.call(cbind, ps)
  x_osc <- x - tcrossprod(t_ortho, p_ortho)

  R2 <- sum(x_osc^2) / sum(x_original^2) * 100
  angle <- crossprod(t_ortho, y)
  norm <- MASS::ginv(sqrt(apply(t_ortho^2, 2, sum) * sum(y^2)))
  angle <- t(angle) %*% t(norm)
  angle <- mean(acos(angle) * 180 / pi)

  res <- list(
    "correction" = tibble::as_tibble(x_osc),
    "weights" = tibble::as_tibble(w_ortho),
    "scores" = tibble::as_tibble(t_ortho),
    "loadings" = tibble::as_tibble(p_ortho),
    "angle" = angle,
    "R2" = R2
  )
  return(res)
}
```
:::
